---
title: 'Problem Set 2.1: Comparing multiple means'
author: "CHEN"
date: "2024-01-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# The problem with jelly beans

Already got a simulation of the study done in the comic (https://xkcd.com/882/).

Import the file *jellybeans.csv*.

```{r import data, echo = FALSE, comment="##"}
jellybeans <- read.csv("jellybeans.csv")
head(jellybeans)
unique(jellybeans$colour)
```
Check the groups by colour in the data.

For the simulation, we imagined that acne is measured by the presence of an “acne score”, which is normally distributed with a mean of 0 and standard deviation of 1.

```{r plot the simulation, comment="##"}
# still need some efforts in changing colors
g <- ggplot(data=jellybeans, aes(x=colour,y=score))
g1 <- g + geom_boxplot() +
  labs(x = "Colours", y = "Score")
  theme(legend.position = "right")
g1
```

## Madness of multiple t-tests

We established in lecture that multiple t-test massively increase the probability of a false positive result.
Even if researchers only compared each colour to control (and not different colours to each other), how many t-tests is that? 

```{r number of t-tests, echo = FALSE, comment="##"}
groups <- unique(jellybeans$colour)
length(groups)-1
```

What is the false positive probability?

```{r false positive probability, comment="##"}
# calculate the false positive probability of the multiple t-tests
1-0.95^(length(groups)-1)
```
Confirm that at least one of the t-tests does indeed give a false positive result. (No need to systematically compare everything - have a look at the plot first and look for a comparison that you suspect would give a significant result)

## Can we look at variance instead?

If we only want to know whether at least 2 out of the 21 conditions are different from each other, we could do so by looking at differences within and between groups again. Remember, we said in lecture that we want to find out whether the difference between two data points can be explained by them being in different groups.

You can use a similar method to what you did in the practical to repeatedly draw samples of two and take note of the (absolute) difference between them and of whether they come from the same or different groups.

Note that you would probably need more iterations than you had for the practical. Why?

```{r draw samples from 2 groups, comment="##"}
# create empty dataframe for data filling
differences <- data.frame(matrix(nrow = 1000, ncol = 2))

for (i in 1:1000) {
# choose 2 (different) rows from the total number of rows
  sample_index <- sample(1:nrow(jellybeans),2)
# read out those two rows from trial. This is your sample
# (maybe save it as a separate object, but it's not necessary)
  sample <- jellybeans[sample_index,]
# For the two points in your sample, read out the pain indices
# and determine their absolute difference
  difference <- abs(sample$score[1]-sample$score[2])
# For the two points in your sample, decide whether they belong
# to the same or to different treatment groups
  if (sample$colour[1]==sample$colour[2]) {
    differences[i,] <- c('same',difference)
  } else {
    differences[i,] <- c('different',difference)
  }
}

# set column names
colnames(differences) <- c('colours','dif')

# change data types
differences$dif <- as.numeric(differences$dif)

# Conduct a Wilcoxon rank sum test
wilcox.test(dif~colours, data = differences, alternative = "two.sided")
```

# There is a difference, what now?

Let’s assume we looked at within group and between group differences in some study and concluded that the four groups are NOT the same. But what now? How do we know what groups exactly are different from each other?

Remember we said that running 6 individual t-tests would give us an effective false positive probability (if H0 is true) of more than 25 %.

But could we adjust the α level for each individual t-test so that the overall false positive probability remains at 0.05? If so, how?

Yes, there is a way for adjustment. We can change the alpha level for each individual t-test to:
```{r calculate adjusted alpha level, comment="##"}
0.95^(1/3)
```
Therefore, the error can be reduced.















